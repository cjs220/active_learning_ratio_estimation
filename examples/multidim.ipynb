{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the code below to install active_learning_ratio_estimation from source\n",
    "# if you do not do this, unless you already have it installed in this environment, this notebook will not run\n",
    "\n",
    "import os, sys, tempfile\n",
    "original_dir = os.getcwd()\n",
    "REPO_NAME = 'active_learning_ratio_estimation'\n",
    "BRANCH = 'master'\n",
    "tempdir = tempfile.gettempdir()\n",
    "os.chdir(tempdir)\n",
    "os.system(f'git clone --single-branch --branch {BRANCH} https://github.com/cjs220/{REPO_NAME}.git')\n",
    "sys.path.insert(0, os.path.join(tempdir, REPO_NAME))\n",
    "os.chdir(original_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from sklearn import clone\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.datasets import make_sparse_spd_matrix\n",
    "\n",
    "from active_learning_ratio_estimation.model import SinglyParameterizedRatioModel, DenseClassifier, FlipoutClassifier\n",
    "from active_learning_ratio_estimation.dataset import ParamGrid, SinglyParameterizedRatioDataset\n",
    "\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDimToyModel(tfd.TransformedDistribution):\n",
    "\n",
    "    def __init__(self, alpha, beta):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "        # compose linear transform\n",
    "        R = make_sparse_spd_matrix(5, alpha=0.5, random_state=7).astype(np.float32)\n",
    "        self.R = R\n",
    "        transform = tf.linalg.LinearOperatorFullMatrix(R)\n",
    "        bijector = tfp.bijectors.AffineLinearOperator(scale=transform)\n",
    "\n",
    "        super().__init__(distribution=self.z_distribution, bijector=bijector)\n",
    "\n",
    "    @property\n",
    "    def z_distribution(self):\n",
    "        z_distribution = tfd.Blockwise([\n",
    "            tfd.Normal(loc=self.alpha, scale=1),  # z1\n",
    "            tfd.Normal(loc=self.beta, scale=3),  # z2\n",
    "            tfd.MixtureSameFamily(\n",
    "                mixture_distribution=tfd.Categorical(probs=[0.5, 0.5]),\n",
    "                components_distribution=tfd.Normal(\n",
    "                    loc=[-2, 2],\n",
    "                    scale=[1, 0.5]\n",
    "                )\n",
    "            ),  # z3\n",
    "            tfd.Exponential(3),  # z4\n",
    "            tfd.Exponential(0.5),  # z5\n",
    "        ])\n",
    "        return z_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms / correlations of true distributions\n",
    "true_alpha = 1\n",
    "true_beta = -1\n",
    "p_true = MultiDimToyModel(alpha=1, beta=-1)\n",
    "X_true = p_true.sample(500)\n",
    "# fig = corner(X_true, bins=20, smooth=0.85, labels=[\"X0\", \"X1\", \"X2\", \"X3\", \"X4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find exact maximum likelihood\n",
    "var_alpha = tf.Variable(tf.constant(0, dtype=tf.float32))\n",
    "var_beta = tf.Variable(tf.constant(0, dtype=tf.float32))\n",
    "p_var = MultiDimToyModel(var_alpha, var_beta)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "n_iter = int(1e3)\n",
    "nll = tf.function(lambda: -tf.keras.backend.sum(p_var.log_prob(X_true)))\n",
    "\n",
    "for i in range(n_iter):\n",
    "    optimizer.minimize(nll, [var_alpha, var_beta])\n",
    "\n",
    "alpha_mle = var_alpha.numpy()\n",
    "beta_mle = var_beta.numpy()\n",
    "theta_mle = np.array([alpha_mle, beta_mle])\n",
    "max_log_prob = p_var.log_prob(X_true)\n",
    "\n",
    "print(f'Exact MLE: alpha={alpha_mle}, beta={beta_mle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for fitting\n",
    "param_grid_train = ParamGrid(bounds=[(-3, 3), (-3, 3)], num=30)\n",
    "theta_0 = np.array([alpha_mle, beta_mle])\n",
    "ds = SinglyParameterizedRatioDataset(\n",
    "    simulator_func=MultiDimToyModel,\n",
    "    theta_0=theta_0,\n",
    "    theta_1_iterator=param_grid_train,\n",
    "    n_samples_per_theta=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "epochs = 1\n",
    "patience = 2\n",
    "validation_split = 0.1\n",
    "n_hidden = (40, 40)\n",
    "\n",
    "# create model\n",
    "bayesian_estimator = FlipoutClassifier(n_hidden=n_hidden, activation='relu',\n",
    "                                       epochs=epochs, patience=patience,\n",
    "                                       validation_split=validation_split)\n",
    "model = SinglyParameterizedRatioModel(estimator=bayesian_estimator, calibration_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(clf, grid):\n",
    "    clf.fit(ds)\n",
    "    nllr_pred = clf.nllr_param_scan(x=X_true, param_grid=grid)\n",
    "    return nllr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plot = 50\n",
    "alpha_bounds = (0.75, 1.25)\n",
    "beta_bounds = (-2, 0)\n",
    "plot_grid = ParamGrid(bounds=[alpha_bounds, beta_bounds], num=num_plot)\n",
    "Alphas, Betas = plot_grid.meshgrid()\n",
    "\n",
    "# fit model and predict contours\n",
    "pred_contours = fit_predict(model, grid=plot_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate contours of exact negative log likelihood ratio\n",
    "\n",
    "@tf.function\n",
    "def nllr_exact(alpha, beta, X):\n",
    "    p_theta = MultiDimToyModel(alpha=alpha, beta=beta)\n",
    "    return -tf.keras.backend.sum((p_theta.log_prob(X) - max_log_prob))\n",
    "\n",
    "\n",
    "exact_contours = np.zeros_like(Alphas)\n",
    "for i in range(num_plot):\n",
    "    for j in range(num_plot):\n",
    "        alpha = tf.constant(Alphas[i, j])\n",
    "        beta = tf.constant(Betas[i, j])\n",
    "        nllr = nllr_exact(alpha, beta, X_true)\n",
    "        exact_contours[i, j] = nllr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot exact and predicted contours\n",
    "\n",
    "\n",
    "def plot_contours(contours, ax):\n",
    "    ax.contour(*plot_grid.meshgrid(), 2 * contours, levels=[chi2.ppf(0.683, df=2),\n",
    "                                                            chi2.ppf(0.9545, df=2),\n",
    "                                                            chi2.ppf(0.9973, df=2)], colors=[\"w\"])\n",
    "    ax.contourf(*plot_grid.meshgrid(), 2 * contours, vmin=0, vmax=30)\n",
    "    ax.plot([true_alpha], [true_beta], \"ro\", markersize=8, label='True')\n",
    "    ax.plot([alpha_mle], [beta_mle], \"go\", markersize=8, label='MLE')\n",
    "    ax.set_xlim(*alpha_bounds)\n",
    "    ax.set_ylim(*beta_bounds)\n",
    "    ax.set_xlabel(r\"$\\alpha$\")\n",
    "    ax.set_ylabel(r\"$\\beta$\")\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(2, sharex=True)\n",
    "for i, contours in enumerate([exact_contours, pred_contours]):\n",
    "    plot_contours(contours, ax=axarr[i])\n",
    "\n",
    "axarr[0].legend(loc='upper center', fancybox=True, shadow=True)\n",
    "contour_mae = np.abs(pred_contours - exact_contours).mean()\n",
    "print('Contour MAE: ', contour_mae)\n",
    "plt.savefig('contours.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
