{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the code below to install active_learning_ratio_estimation from source\n",
    "# if you do not do this, unless you already have it installed in this environment, this notebook will not run\n",
    "\n",
    "import os, sys, tempfile\n",
    "original_dir = os.getcwd()\n",
    "REPO_NAME = 'active_learning_ratio_estimation'\n",
    "BRANCH = 'master'\n",
    "tempdir = tempfile.gettempdir()\n",
    "os.chdir(tempdir)\n",
    "os.system(f'git clone --single-branch --branch {BRANCH} https://github.com/cjs220/{REPO_NAME}.git')\n",
    "sys.path.insert(0, os.path.join(tempdir, REPO_NAME))\n",
    "os.chdir(original_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn import clone\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from active_learning_ratio_estimation.dataset import UnparameterizedRatioDataset\n",
    "from active_learning_ratio_estimation.util import ideal_classifier_probs_from_simulator, negative_log_likelihood_ratio\n",
    "from active_learning_ratio_estimation.model import UnparameterizedRatioModel, DenseClassifier, FlipoutClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_mixture(gamma):\n",
    "    mixture_probs = [\n",
    "        0.5 * (1 - gamma),\n",
    "        0.5 * (1 - gamma),\n",
    "        gamma\n",
    "    ]\n",
    "    gaussians = [\n",
    "        tfd.Normal(loc=-2, scale=0.75),\n",
    "        tfd.Normal(loc=0, scale=2),\n",
    "        tfd.Normal(loc=1, scale=0.5)\n",
    "    ]\n",
    "    dist = tfd.Mixture(\n",
    "        cat=tfd.Categorical(probs=mixture_probs),\n",
    "        components=gaussians\n",
    "    )\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "theta_0 = 0.05\n",
    "theta_1 = 0.00\n",
    "n_samples_per_theta = int(1e5)\n",
    "\n",
    "ds = UnparameterizedRatioDataset(\n",
    "    n_samples_per_theta=n_samples_per_theta,\n",
    "    simulator_func=triple_mixture,\n",
    "    theta_0=theta_0,\n",
    "    theta_1=theta_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "epochs = 2\n",
    "patience = 5\n",
    "validation_split = 0.1\n",
    "n_hidden = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular, uncalibrated model\n",
    "regular_estimator = DenseClassifier(n_hidden=n_hidden, activation='tanh',\n",
    "                                    epochs=epochs, patience=patience,\n",
    "                                    validation_split=validation_split)\n",
    "regular_uncalibrated = UnparameterizedRatioModel(estimator=regular_estimator, calibration_method=None,\n",
    "                                                 normalize_input=False)\n",
    "\n",
    "# bayesian, uncalibrated model\n",
    "bayesian_estimator = FlipoutClassifier(n_hidden=n_hidden, activation='relu',\n",
    "                                       epochs=epochs, patience=patience,\n",
    "                                       validation_split=validation_split)\n",
    "bayesian_uncalibrated = UnparameterizedRatioModel(estimator=bayesian_estimator, calibration_method=None,\n",
    "                                                  normalize_input=False)\n",
    "\n",
    "# regular, calibrated model\n",
    "cv = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=1)\n",
    "regular_calibrated = UnparameterizedRatioModel(estimator=clone(regular_estimator), calibration_method='sigmoid',\n",
    "                                               normalize_input=False, cv=cv)\n",
    "\n",
    "models = {\n",
    "    'Regular Uncalibrated': regular_uncalibrated,\n",
    "    'Bayesian Uncalibrated': bayesian_uncalibrated,\n",
    "    'Regular Calibrated': regular_calibrated\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, int(1e4))\n",
    "\n",
    "\n",
    "def fit_and_predict(clf):\n",
    "    clf.fit(ds)\n",
    "    y_pred = clf.predict_proba(x)[:, 1].squeeze()\n",
    "    nllr = clf.predict_negative_log_likelihood_ratio(x).squeeze()\n",
    "    return y_pred, nllr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict models\n",
    "y_preds = dict()\n",
    "nllrs = dict()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f'\\n******* Fitting {model_name} *******\\n')\n",
    "    y_pred, nllr = fit_and_predict(model)\n",
    "    y_preds[model_name] = y_pred\n",
    "    nllrs[model_name] = nllr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ideal predictions\n",
    "y_preds['Ideal'] = ideal_classifier_probs_from_simulator(x, triple_mixture, theta_0, theta_1)\n",
    "nllrs['True'] = negative_log_likelihood_ratio(x, triple_mixture, theta_0, theta_1)\n",
    "y_preds = pd.DataFrame(y_preds, index=x)\n",
    "nllrs = pd.DataFrame(nllrs, index=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for classifier decision function\n",
    "y_preds.plot()\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([0.4, 0.55])\n",
    "plt.title('Classifier predicted probabilities')\n",
    "plt.xlabel('$x$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for negative log likelihood ratio\n",
    "nllrs.plot()\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-0.2, 0.5])\n",
    "plt.title('Negative log-likelihood ratio')\n",
    "plt.xlabel('$x$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE between models' predicted probabilities and ideal probabilities \n",
    "mses = pd.Series(dtype=float)\n",
    "\n",
    "for model_name in models:\n",
    "    mse = np.mean((y_preds[model_name] - y_preds['Ideal']) ** 2)\n",
    "    mses[model_name] = mse\n",
    "\n",
    "plt.figure()\n",
    "mses.plot.bar(fontsize=16, rot=30)\n",
    "plt.title('Mean squared error between\\nclassifier predictions and ideal', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
